{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e535945a",
   "metadata": {},
   "source": [
    "#  Steps:\n",
    "\n",
    "1. Problem Statement\n",
    "\n",
    "2. Data Collection and preprocessing\n",
    "\n",
    "3. EDA\n",
    "\n",
    "4. Solving Class Imbalance Problem\n",
    "\n",
    "5. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d0abb",
   "metadata": {},
   "source": [
    "# 1. Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f75cfc",
   "metadata": {},
   "source": [
    "To build a machine learning model to identify fraudulent credit card\n",
    "transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7444d6",
   "metadata": {},
   "source": [
    "### 2. Data Collection and Preprocessing\n",
    "\n",
    "I am using the data from : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/\n",
    "\n",
    "About the data:\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d44002",
   "metadata": {},
   "source": [
    "# 2.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61500dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "# importing necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# importing models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# libaries for under sampling \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# importing evaluation metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "credit_card_df=pd.read_csv('creditcard.csv')\n",
    "credit_card_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f6d8b",
   "metadata": {},
   "source": [
    "# 2.2 Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of the dataset\n",
    "credit_card_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the  dataset info\n",
    "credit_card_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in the data\n",
    "credit_card_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2556fe",
   "metadata": {},
   "source": [
    "There are no null values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe08e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any duplicate data in the dataset\n",
    "credit_card_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates data\n",
    "credit_card_df=credit_card_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb71048",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df['Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef472d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data\n",
    "# All the feature from v1-v28 are already in normalised form only amount needs to be normalised\n",
    "# using StandardScaler to normalise the amount feature\n",
    "\n",
    "scaler=StandardScaler()\n",
    "credit_card_df['Amount']=scaler.fit_transform(pd.DataFrame(credit_card_df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7f6f5",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(credit_card_df.corr(), cmap='YlGnBu', annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(credit_card_df, hue='species', palette='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56423034",
   "metadata": {},
   "source": [
    "# 4. Solving Class Imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea236f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for traget variable\n",
    "credit_card_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df['Class'].value_counts().plot(kind='bar', color=['red','blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462f1db",
   "metadata": {},
   "source": [
    "It seems there is a class imbalance problem in the target variable where the fraud which is 1 which is very low in number as compare to non fraudulent transaction. To solve the class imbalance problem I am goign to use random Under-sampling which is removing some data from non-fraudulent util it is balance with the fraudulent transaction data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18fabf",
   "metadata": {},
   "source": [
    "# Random Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into X and y\n",
    "X=credit_card_df.drop('Class', axis=1)\n",
    "y=credit_card_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10472de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random under-sampling\n",
    "rus=RandomUnderSampler(random_state=42, replacement=True)\n",
    "x_rus,y_rus=rus.fit_resample(X_train,y_train)\n",
    "\n",
    "x_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e553d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution before and after sampling\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot original class distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Original Class Distribution\")\n",
    "\n",
    "# Plot class distribution after SMOTE\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=y_rus)\n",
    "plt.title(\"Class Distribution After Under-sampling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313970d2",
   "metadata": {},
   "source": [
    "Now the class is balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094373c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427e8549",
   "metadata": {},
   "source": [
    "# 4. Machine learning model implementation\n",
    "\n",
    "For model i will be testing the below models:\n",
    "\n",
    "1. RandomForestClassifier\n",
    "\n",
    "2. Logistic Regression\n",
    "\n",
    "3. Support Vector Machines\n",
    "\n",
    "4. Gradient Boosting Models(XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={'Logistic Regression':LogisticRegression(),\n",
    "        'Random Forest Classifier':RandomForestClassifier(),\n",
    "       'Support Vector Machine':SVC(),\n",
    "       'XGBoost':XGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66077cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to fit and score models\n",
    "def fit_and_score(models, X_train,X_test, y_train, y_test):\n",
    "    # set random seed\n",
    "    np.random.seed(42)\n",
    "    #make a dictionary to keep model scores\n",
    "    model_scores=[]\n",
    "    #Loop through models\n",
    "    for name,model in models.items():\n",
    "        # Fit the model\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred=model.predict(X_test)\n",
    "        \n",
    "#         save the trained model to use it later using joblib library\n",
    "        model_filename = f\"{name}_model.pkl\"\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Model {name} saved as {model_filename}\")\n",
    "        \n",
    "        #Evaluate the model and append its score\n",
    "        print(f\"Evaluating {name}....\")\n",
    "        report_dict=classification_report(y_test,y_pred, output_dict=True)\n",
    "        \n",
    "                # Extract relevant metrics from the classification report\n",
    "        precision_0 = report_dict['0']['precision']\n",
    "        recall_0 = report_dict['0']['recall']\n",
    "        f1_0 = report_dict['0']['f1-score']\n",
    "        \n",
    "        precision_1 = report_dict['1']['precision']\n",
    "        recall_1 = report_dict['1']['recall']\n",
    "        f1_1 = report_dict['1']['f1-score']\n",
    "\n",
    "        model_scores.append({\n",
    "            'Model': name,\n",
    "            'Precision_0': precision_0,\n",
    "            'Recall_0': recall_0,\n",
    "            'F1_0': f1_0,\n",
    "            'Precision_1': precision_1,\n",
    "            'Recall_1': recall_1,\n",
    "            'F1_1': f1_1\n",
    "        })\n",
    "        \n",
    "    model_scores=pd.DataFrame(model_scores)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores=fit_and_score(models=models, X_train=x_rus,X_test=X_test,y_train=y_rus ,y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4958a1",
   "metadata": {},
   "source": [
    "Random Forest Classifier is performing well because it maintains a high precision, recall, and F1-Score for non-fraudulent transactions (class 0), and it also achieves a good balance between precision and recall for fraudulent transactions (class 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# Melt the DataFrame to make it suitable for plotting\n",
    "df_melted = pd.melt(model_scores, id_vars=['Model'], var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Model', y='Score', hue='Metric', data=df_melted, palette='viridis')\n",
    "plt.title('Model Comparison - Precision, Recall, and F1-Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376c23b",
   "metadata": {},
   "source": [
    "Let's try Random Over Sampling to imbalance the class and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a442b",
   "metadata": {},
   "source": [
    "# Random Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros=RandomOverSampler(random_state=42)\n",
    "x_ros,y_ros=ros.fit_resample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution before and after sampling\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot original class distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Original Class Distribution\")\n",
    "\n",
    "# Plot class distribution after SMOTE\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x=y_ros)\n",
    "plt.title(\"Class Distribution After Over-sampling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ad94a",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "Since randomforest classifer was performing well in under sampling i am going to use random forest classifer in random over-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491534e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cda1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores=fit_and_score(models=rf, X_train=x_ros,X_test=X_test,y_train=y_ros ,y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d45756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
